{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMMPn+FXuPpcsj8/pQl1OMm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AryanPROFFESOR/AryanPROFFESOR/blob/main/skeleton_neuron_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fh4AYCa65whr",
        "outputId": "8d4f28d0-fef1-412c-9854-60b61db1f84e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All dependencies installed successfully.\n"
          ]
        }
      ],
      "source": [
        "# === Cell 0: Dependencies & globals (Python 3 / Google Colab) ===\n",
        "\n",
        "# Install required packages\n",
        "!pip install -q pandas numpy scipy vcfpy\n",
        "\n",
        "# Imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.stats as stats\n",
        "\n",
        "from typing import Dict, List, Tuple, Any\n",
        "\n",
        "import vcfpy\n",
        "\n",
        "print(\"All dependencies installed successfully.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 0: Install dependencies (REQUIRED) ===\n",
        "!pip install -q vcfpy pandas numpy scipy\n"
      ],
      "metadata": {
        "id": "-WxkqQQQ7Wbz"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 1: Module 0A — VariantParser ===\n",
        "\n",
        "import vcfpy\n",
        "import pandas as pd\n",
        "from typing import Dict, List, Any\n",
        "\n",
        "class VariantParser:\n",
        "    \"\"\"\n",
        "    Parse VCF files and annotate epilepsy-related genes.\n",
        "    EXACTLY as defined in markdown, with validation guards.\n",
        "    \"\"\"\n",
        "\n",
        "    EPILEPSY_GENES = {\n",
        "        'Na': ['SCN1A', 'SCN2A', 'SCN8A', 'SCN9A'],\n",
        "        'K': ['KCNQ2', 'KCNQ3', 'KCNA1', 'KCNT1', 'KCNB1'],\n",
        "        'Ca': ['CACNA1A', 'CACNA1G', 'CACNB4'],\n",
        "        'Cl': ['GABRG2', 'GABRA1', 'SLC6A1'],\n",
        "        'Gap': ['GJA1', 'GJB1'],\n",
        "        'Synapse': ['PCDH19', 'STXBP1', 'CNTNAP2']\n",
        "    }\n",
        "\n",
        "    def __init__(self, vcf_path: str):\n",
        "        self.vcf_path = vcf_path\n",
        "        self.variants = self._load_vcf()\n",
        "\n",
        "    def _load_vcf(self) -> List[Dict[str, Any]]:\n",
        "        \"\"\"Load and parse VCF file.\"\"\"\n",
        "        variants = []\n",
        "        reader = vcfpy.Reader.from_path(self.vcf_path)\n",
        "\n",
        "        for record in reader:\n",
        "            ann = record.INFO.get('ANN', [''])[0]\n",
        "            variants.append({\n",
        "                'CHROM': record.CHROM,\n",
        "                'POS': record.POS,\n",
        "                'REF': str(record.REF),\n",
        "                'ALT': str(record.ALT[0].value) if record.ALT else None,\n",
        "                'QUAL': record.QUAL,\n",
        "                'ANN': ann,\n",
        "                'GENE': self._extract_gene(ann)\n",
        "            })\n",
        "        return variants\n",
        "\n",
        "    def _extract_gene(self, ann_field: str) -> str:\n",
        "        \"\"\"\n",
        "        Conservative gene extraction from ANN field.\n",
        "        ANN format varies; this avoids false positives.\n",
        "        \"\"\"\n",
        "        for genes in self.EPILEPSY_GENES.values():\n",
        "            for g in genes:\n",
        "                if g in ann_field:\n",
        "                    return g\n",
        "        return \"UNKNOWN\"\n",
        "\n",
        "    def filter_epilepsy_genes(self) -> pd.DataFrame:\n",
        "        \"\"\"Filter to epilepsy-related genes only.\"\"\"\n",
        "        df = pd.DataFrame(self.variants)\n",
        "        df = df[df['GENE'] != \"UNKNOWN\"].reset_index(drop=True)\n",
        "        return df\n",
        "\n",
        "    def annotate_impact(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Add functional impact predictions.\n",
        "        Placeholders preserved exactly as markdown.\n",
        "        \"\"\"\n",
        "        df['IMPACT_SIFT'] = self._predict_sift(df)\n",
        "        df['IMPACT_POLYPHEN'] = self._predict_polyphen(df)\n",
        "        df['IMPACT_CADD'] = self._predict_cadd(df)\n",
        "        return df\n",
        "\n",
        "    def _predict_sift(self, df: pd.DataFrame) -> List[float]:\n",
        "        return [0.5] * len(df)\n",
        "\n",
        "    def _predict_polyphen(self, df: pd.DataFrame) -> List[float]:\n",
        "        return [0.5] * len(df)\n",
        "\n",
        "    def _predict_cadd(self, df: pd.DataFrame) -> List[float]:\n",
        "        return [15.0] * len(df)\n"
      ],
      "metadata": {
        "id": "Ux71HGuPr7J3"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 2: Module 0B — ProteinStructureAnalyzer ===\n",
        "\n",
        "from scipy.optimize import minimize\n",
        "from typing import Dict, Any, Tuple\n",
        "\n",
        "class ProteinStructureAnalyzer:\n",
        "    \"\"\"\n",
        "    Evaluate structural feasibility of variants.\n",
        "    Implements ALL markdown constraints without removing placeholders.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, gene_id: str, variant: Dict[str, Any]):\n",
        "        self.gene_id = gene_id\n",
        "        self.variant = variant\n",
        "        self.wt_structure = self._fetch_alphafold_structure(gene_id)\n",
        "\n",
        "    def _fetch_alphafold_structure(self, gene_id: str):\n",
        "        \"\"\"\n",
        "        Placeholder — structural fetch.\n",
        "        Preserved exactly as markdown.\n",
        "        \"\"\"\n",
        "        return None\n",
        "\n",
        "    def calculate_folding_energy(self) -> Tuple[float, float, float]:\n",
        "        \"\"\"\n",
        "        Calculate folding energy difference.\n",
        "        Returns (ΔG_wt, ΔG_variant, ΔΔG)\n",
        "        \"\"\"\n",
        "        dg_wt = -8.5     # kcal/mol (example)\n",
        "        dg_variant = -6.2\n",
        "        delta_delta_g = dg_variant - dg_wt\n",
        "        return dg_wt, dg_variant, delta_delta_g\n",
        "\n",
        "    def check_membrane_insertion(self) -> bool:\n",
        "        \"\"\"\n",
        "        Membrane insertion constraint.\n",
        "        Preserved as boolean gate.\n",
        "        \"\"\"\n",
        "        return True\n",
        "\n",
        "    def evaluate_gating_motif(self) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        Structural integrity scores ∈ [0,1]\n",
        "        \"\"\"\n",
        "        return {\n",
        "            'voltage_sensor_integrity': 0.95,\n",
        "            'inactivation_domain_integrity': 0.88,\n",
        "            'pore_domain_integrity': 0.92\n",
        "        }\n",
        "\n",
        "    def filter_pass_feasibility(self) -> bool:\n",
        "        \"\"\"\n",
        "        EXACT feasibility cascade from markdown.\n",
        "        No shortcuts, no relaxation.\n",
        "        \"\"\"\n",
        "\n",
        "        _, _, delta_delta_g = self.calculate_folding_energy()\n",
        "        if delta_delta_g > 3.0:\n",
        "            return False\n",
        "\n",
        "        if not self.check_membrane_insertion():\n",
        "            return False\n",
        "\n",
        "        motifs = self.evaluate_gating_motif()\n",
        "        for score in motifs.values():\n",
        "            if score < 0.85:\n",
        "                return False\n",
        "\n",
        "        return True\n"
      ],
      "metadata": {
        "id": "vRfpwqDAsBh3"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 3: Combined Layer 0 Execution ===\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "def run_layer_0(vcf_path: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Executes Module 0A + 0B exactly as pipeline expects.\n",
        "    \"\"\"\n",
        "\n",
        "    parser = VariantParser(vcf_path)\n",
        "    df = parser.filter_epilepsy_genes()\n",
        "    df = parser.annotate_impact(df)\n",
        "\n",
        "    feasible_variants = []\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        analyzer = ProteinStructureAnalyzer(row['GENE'], row.to_dict())\n",
        "        if analyzer.filter_pass_feasibility():\n",
        "            feasible_variants.append(row)\n",
        "\n",
        "    return pd.DataFrame(feasible_variants)\n"
      ],
      "metadata": {
        "id": "-qghTo1ksXfE"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 5: Module 1A — Variant Feasibility Filter ===\n",
        "\n",
        "class VariantFeasibilityFilter:\n",
        "    \"\"\"\n",
        "    Module 1A\n",
        "    Purpose:\n",
        "    - Accepts output of Layer 0\n",
        "    - Applies NO new rules\n",
        "    - Only enforces that structural feasibility == True\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, feasible_variants_df):\n",
        "        self.df = feasible_variants_df\n",
        "\n",
        "    def pass_variants(self):\n",
        "        \"\"\"\n",
        "        Markdown specifies:\n",
        "        - Variants passed from Module 0B\n",
        "        - No additional rejection logic\n",
        "        \"\"\"\n",
        "        return self.df.copy()\n"
      ],
      "metadata": {
        "id": "d5W4HGAFvBrq"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 6: Module 1B — Markov Channel State Solver ===\n",
        "\n",
        "import numpy as np\n",
        "from scipy.linalg import null_space\n",
        "\n",
        "class MarkovChannelSolver:\n",
        "    \"\"\"\n",
        "    Implements:\n",
        "    C ↔ O ↔ I Markov model\n",
        "    As specified in markdown.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, gene, temperature_celsius=37.0):\n",
        "        self.gene = gene\n",
        "        self.T = 273.15 + temperature_celsius\n",
        "        self.R = 8.314\n",
        "        self.F = 96485\n",
        "\n",
        "        # Base WT parameters (placeholders exactly as markdown)\n",
        "        self.params = {\n",
        "            'k0_CO': 0.5,\n",
        "            'k0_OC': 0.2,\n",
        "            'k0_OI': 0.1,\n",
        "            'k0_IO': 0.05,\n",
        "            'Ea_CO': 35000,\n",
        "            'Ea_OC': 40000,\n",
        "            'Ea_OI': 38000,\n",
        "            'Ea_IO': 42000,\n",
        "            'z_CO': 0.8,\n",
        "            'z_OC': -0.3,\n",
        "            'z_OI': 0.5,\n",
        "            'z_IO': -0.2\n",
        "        }\n",
        "\n",
        "    def rate(self, k0, Ea, z, V):\n",
        "        return k0 * np.exp(-Ea / (self.R * self.T)) * np.exp(z * self.F * V / (self.R * self.T))\n",
        "\n",
        "    def build_Q(self, V, variant_effect=None):\n",
        "        \"\"\"\n",
        "        Build transition matrix Q.\n",
        "        Variant effects are multiplicative, as per markdown.\n",
        "        \"\"\"\n",
        "\n",
        "        p = self.params.copy()\n",
        "\n",
        "        if variant_effect == \"loss-of-function\":\n",
        "            p['k0_OI'] *= 1.4\n",
        "            p['k0_IO'] *= 0.7\n",
        "        elif variant_effect == \"gain-of-function\":\n",
        "            p['k0_OI'] *= 0.6\n",
        "            p['k0_IO'] *= 1.3\n",
        "\n",
        "        k_CO = self.rate(p['k0_CO'], p['Ea_CO'], p['z_CO'], V)\n",
        "        k_OC = self.rate(p['k0_OC'], p['Ea_OC'], p['z_OC'], V)\n",
        "        k_OI = self.rate(p['k0_OI'], p['Ea_OI'], p['z_OI'], V)\n",
        "        k_IO = self.rate(p['k0_IO'], p['Ea_IO'], p['z_IO'], V)\n",
        "\n",
        "        Q = np.array([\n",
        "            [-k_CO,          k_CO,        0.0],\n",
        "            [ k_OC, -(k_OC + k_OI),       k_OI],\n",
        "            [ 0.0,            k_IO,     -k_IO]\n",
        "        ])\n",
        "\n",
        "        return Q\n",
        "\n",
        "    def steady_state_open_probability(self, V, variant_effect=None):\n",
        "        \"\"\"\n",
        "        Solve Qᵀ p = 0\n",
        "        \"\"\"\n",
        "        Q = self.build_Q(V, variant_effect)\n",
        "        ns = null_space(Q.T)\n",
        "        p = ns[:, 0]\n",
        "        p /= np.sum(p)\n",
        "        return float(p[1])\n"
      ],
      "metadata": {
        "id": "dFtvO_14vF2B"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 7: Module 1C — HH Parameter Generator ===\n",
        "\n",
        "import numpy as np\n",
        "from scipy.interpolate import UnivariateSpline\n",
        "\n",
        "class HHParameterGenerator:\n",
        "    \"\"\"\n",
        "    Converts Markov open probability into HH parameters.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, markov_solver, variant_effect=None):\n",
        "        self.markov = markov_solver\n",
        "        self.variant_effect = variant_effect\n",
        "        self.V = np.linspace(-90e-3, 50e-3, 300)\n",
        "\n",
        "    def generate(self):\n",
        "        p_open = np.array([\n",
        "            self.markov.steady_state_open_probability(V, self.variant_effect)\n",
        "            for V in self.V\n",
        "        ])\n",
        "\n",
        "        spline = UnivariateSpline(self.V * 1e3, p_open - 0.5, s=0)\n",
        "        V_half = float(spline.roots()[0])\n",
        "\n",
        "        gbar = 120 * np.max(p_open)\n",
        "\n",
        "        return {\n",
        "            'gbar': gbar,\n",
        "            'V_half_m': V_half,\n",
        "            'p_open_curve': p_open\n",
        "        }\n"
      ],
      "metadata": {
        "id": "GbYSUrrbvIKx"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 8: Run Layer 1 ===\n",
        "\n",
        "def run_layer_1(feasible_variants_df):\n",
        "    \"\"\"\n",
        "    Executes Module 1A → 1B → 1C\n",
        "    \"\"\"\n",
        "\n",
        "    feasibility = VariantFeasibilityFilter(feasible_variants_df)\n",
        "    variants = feasibility.pass_variants()\n",
        "\n",
        "    hh_param_sets = []\n",
        "\n",
        "    for _, row in variants.iterrows():\n",
        "        solver = MarkovChannelSolver(row['GENE'])\n",
        "        hh_gen = HHParameterGenerator(\n",
        "            solver,\n",
        "            variant_effect=\"gain-of-function\"  # placeholder as per markdown\n",
        "        )\n",
        "        hh_param_sets.append(hh_gen.generate())\n",
        "\n",
        "    return hh_param_sets\n"
      ],
      "metadata": {
        "id": "z_fZ7KcXvK3X"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 9: Module 2A — Hodgkin–Huxley Dynamics Solver ===\n",
        "\n",
        "import numpy as np\n",
        "from scipy.integrate import odeint\n",
        "\n",
        "class HodgkinHuxleyModel:\n",
        "    \"\"\"\n",
        "    Classic HH neuron model.\n",
        "    No population, no noise, no bursting.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, params):\n",
        "        self.Cm = 1.0\n",
        "        self.gNa = params['gbar']\n",
        "        self.gK = 36.0\n",
        "        self.gL = 0.3\n",
        "        self.ENa = 50.0\n",
        "        self.EK = -77.0\n",
        "        self.EL = -54.4\n",
        "\n",
        "    def alpha_m(self, V): return 0.1*(V+40)/(1-np.exp(-(V+40)/10))\n",
        "    def beta_m(self, V):  return 4*np.exp(-(V+65)/18)\n",
        "\n",
        "    def alpha_h(self, V): return 0.07*np.exp(-(V+65)/20)\n",
        "    def beta_h(self, V):  return 1/(1+np.exp(-(V+35)/10))\n",
        "\n",
        "    def alpha_n(self, V): return 0.01*(V+55)/(1-np.exp(-(V+55)/10))\n",
        "    def beta_n(self, V):  return 0.125*np.exp(-(V+65)/80)\n",
        "\n",
        "    def derivatives(self, y, t, I):\n",
        "        V, m, h, n = y\n",
        "\n",
        "        INa = self.gNa * m**3 * h * (V - self.ENa)\n",
        "        IK  = self.gK * n**4 * (V - self.EK)\n",
        "        IL  = self.gL * (V - self.EL)\n",
        "\n",
        "        dVdt = (I - INa - IK - IL) / self.Cm\n",
        "        dmdt = self.alpha_m(V)*(1-m) - self.beta_m(V)*m\n",
        "        dhdt = self.alpha_h(V)*(1-h) - self.beta_h(V)*h\n",
        "        dndt = self.alpha_n(V)*(1-n) - self.beta_n(V)*n\n",
        "\n",
        "        return [dVdt, dmdt, dhdt, dndt]\n",
        "\n",
        "    def simulate(self, I, t):\n",
        "        y0 = [-65, 0.05, 0.6, 0.32]\n",
        "        sol = odeint(self.derivatives, y0, t, args=(I,))\n",
        "        return sol\n"
      ],
      "metadata": {
        "id": "uvTQ2ZYzwW8k"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 10: Module 2B — Morris–Lecar Analyzer ===\n",
        "\n",
        "import numpy as np\n",
        "from scipy.optimize import fsolve\n",
        "\n",
        "class MorrisLecarModel:\n",
        "    \"\"\"\n",
        "    Reduced 2D excitability model.\n",
        "    Used ONLY for bifurcation and stability.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.gCa = 4.4\n",
        "        self.gK = 8.0\n",
        "        self.gL = 2.0\n",
        "        self.VCa = 120\n",
        "        self.VK = -84\n",
        "        self.VL = -60\n",
        "\n",
        "    def m_inf(self, V):\n",
        "        return 0.5 * (1 + np.tanh((V + 1) / 15))\n",
        "\n",
        "    def w_inf(self, V):\n",
        "        return 0.5 * (1 + np.tanh((V - 10) / 14))\n",
        "\n",
        "    def tau_w(self, V):\n",
        "        return 1 / np.cosh((V - 10) / 28)\n",
        "\n",
        "    def equations(self, vars, I):\n",
        "        V, w = vars\n",
        "        dV = I - self.gCa*self.m_inf(V)*(V-self.VCa) \\\n",
        "               - self.gK*w*(V-self.VK) \\\n",
        "               - self.gL*(V-self.VL)\n",
        "        dw = (self.w_inf(V) - w) / self.tau_w(V)\n",
        "        return [dV, dw]\n",
        "\n",
        "    def find_fixed_point(self, I):\n",
        "        return fsolve(self.equations, [-60, 0.2], args=(I,))\n"
      ],
      "metadata": {
        "id": "pSN6y4ijwY4l"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 11: Module 2C — Hindmarsh–Rose Bursting Model ===\n",
        "\n",
        "import numpy as np\n",
        "from scipy.integrate import odeint\n",
        "\n",
        "class HindmarshRoseModel:\n",
        "    \"\"\"\n",
        "    Bursting neuron model.\n",
        "    Independent of HH and ML.\n",
        "    \"\"\"\n",
        "\n",
        "    def equations(self, state, t, I):\n",
        "        x, y, z = state\n",
        "        dx = y - x**3 + 3*x**2 + I - z\n",
        "        dy = 1 - 5*x**2 - y\n",
        "        dz = 0.01 * (4*(x + 1.6) - z)\n",
        "        return [dx, dy, dz]\n",
        "\n",
        "    def simulate(self, I, t):\n",
        "        y0 = [-1.6, 1.0, 3.0]\n",
        "        sol = odeint(self.equations, y0, t, args=(I,))\n",
        "        return sol\n"
      ],
      "metadata": {
        "id": "WeSUylxDwb-1"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 12: Run Layer 2 ===\n",
        "\n",
        "def run_layer_2(hh_param_sets):\n",
        "    \"\"\"\n",
        "    Executes:\n",
        "    - HH dynamics\n",
        "    - Morris–Lecar fixed point\n",
        "    - Hindmarsh–Rose bursting\n",
        "    \"\"\"\n",
        "\n",
        "    results = []\n",
        "\n",
        "    t = np.linspace(0, 50, 5000)\n",
        "\n",
        "    for params in hh_param_sets:\n",
        "        hh = HodgkinHuxleyModel(params)\n",
        "        hh_trace = hh.simulate(I=10, t=t)\n",
        "\n",
        "        ml = MorrisLecarModel()\n",
        "        ml_fp = ml.find_fixed_point(I=10)\n",
        "\n",
        "        hr = HindmarshRoseModel()\n",
        "        hr_trace = hr.simulate(I=3.0, t=t)\n",
        "\n",
        "        results.append({\n",
        "            'HH_trace': hh_trace,\n",
        "            'ML_fixed_point': ml_fp,\n",
        "            'HR_trace': hr_trace\n",
        "        })\n",
        "\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "lDK_MHRzwg_I"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 13: Module 3A — Wilson–Cowan Population Solver ===\n",
        "\n",
        "import numpy as np\n",
        "from scipy.integrate import odeint\n",
        "\n",
        "class WilsonCowanModel:\n",
        "    \"\"\"\n",
        "    Excitatory / Inhibitory population dynamics.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.wEE = 10.0\n",
        "        self.wEI = 12.0\n",
        "        self.wIE = 10.0\n",
        "        self.wII = 2.0\n",
        "        self.thetaE = 3.0\n",
        "        self.thetaI = 3.5\n",
        "        self.tauE = 1.0\n",
        "        self.tauI = 2.0\n",
        "\n",
        "    def S(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def equations(self, y, t, PE, PI):\n",
        "        E, I = y\n",
        "\n",
        "        dE = (-E + self.S(self.wEE*E - self.wEI*I - self.thetaE + PE)) / self.tauE\n",
        "        dI = (-I + self.S(self.wIE*E - self.wII*I - self.thetaI + PI)) / self.tauI\n",
        "\n",
        "        return [dE, dI]\n",
        "\n",
        "    def simulate(self, PE=0.5, PI=0.0, t=None):\n",
        "        if t is None:\n",
        "            t = np.linspace(0, 50, 5000)\n",
        "\n",
        "        y0 = [0.1, 0.1]\n",
        "        sol = odeint(self.equations, y0, t, args=(PE, PI))\n",
        "        return sol\n"
      ],
      "metadata": {
        "id": "HOJlA3TtyE_J"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 14: Module 3B — Synaptic Coupling Module ===\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "class Synapse:\n",
        "    \"\"\"\n",
        "    Simple synaptic current model.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, tau=5.0, gmax=1.0):\n",
        "        self.tau = tau\n",
        "        self.gmax = gmax\n",
        "\n",
        "    def current(self, t, pre_spike_times):\n",
        "        I = 0.0\n",
        "        for ts in pre_spike_times:\n",
        "            if t >= ts:\n",
        "                I += self.gmax * np.exp(-(t - ts) / self.tau)\n",
        "        return I\n"
      ],
      "metadata": {
        "id": "hp5VnnxUyVxR"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 15: Module 3C — Kuramoto Synchronization Model ===\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "class KuramotoModel:\n",
        "    \"\"\"\n",
        "    Phase synchronization model.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, omega, K):\n",
        "        self.omega = omega\n",
        "        self.K = K\n",
        "        self.N = len(omega)\n",
        "\n",
        "    def equations(self, theta, t):\n",
        "        dtheta = np.zeros(self.N)\n",
        "        for i in range(self.N):\n",
        "            coupling = 0.0\n",
        "            for j in range(self.N):\n",
        "                coupling += np.sin(theta[j] - theta[i])\n",
        "            dtheta[i] = self.omega[i] + (self.K / self.N) * coupling\n",
        "        return dtheta\n"
      ],
      "metadata": {
        "id": "GF7ENlFxydNs"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 16: Run Layer 3 ===\n",
        "\n",
        "def run_layer_3():\n",
        "    \"\"\"\n",
        "    Executes population and synchronization models.\n",
        "    \"\"\"\n",
        "\n",
        "    t = np.linspace(0, 50, 5000)\n",
        "\n",
        "    wc = WilsonCowanModel()\n",
        "    wc_sol = wc.simulate(t=t)\n",
        "\n",
        "    syn = Synapse()\n",
        "    syn_current = syn.current(t=10.0, pre_spike_times=[5.0, 7.0, 9.0])\n",
        "\n",
        "    omega = np.random.normal(1.0, 0.1, 20)\n",
        "    kuramoto = KuramotoModel(omega=omega, K=1.5)\n",
        "    theta0 = np.random.uniform(0, 2*np.pi, 20)\n",
        "\n",
        "    return {\n",
        "        'WilsonCowan': wc_sol,\n",
        "        'SynapticCurrent': syn_current,\n",
        "        'KuramotoInitialPhases': theta0\n",
        "    }\n"
      ],
      "metadata": {
        "id": "Dlii-nugyt24"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 17: Module 4A — Network Graph Constructor ===\n",
        "\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "\n",
        "class NetworkTopology:\n",
        "    \"\"\"\n",
        "    Construct network graphs and adjacency matrices.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n_nodes=100):\n",
        "        self.n_nodes = n_nodes\n",
        "\n",
        "    def small_world(self, k=6, p=0.3):\n",
        "        G = nx.watts_strogatz_graph(self.n_nodes, k, p)\n",
        "        return G\n",
        "\n",
        "    def scale_free(self):\n",
        "        G = nx.barabasi_albert_graph(self.n_nodes, m=3)\n",
        "        return G\n",
        "\n",
        "    def adjacency_matrix(self, G):\n",
        "        return nx.to_numpy_array(G)\n"
      ],
      "metadata": {
        "id": "li1MP3C-zqMD"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 18: Module 4B — Jacobian Stability Analyzer ===\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "class JacobianStabilityAnalyzer:\n",
        "    \"\"\"\n",
        "    Analyze network stability via Jacobian eigenvalues.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, adjacency_matrix):\n",
        "        self.A = adjacency_matrix\n",
        "\n",
        "    def compute_eigenvalues(self):\n",
        "        return np.linalg.eigvals(self.A)\n",
        "\n",
        "    def max_real_eigenvalue(self):\n",
        "        eigvals = self.compute_eigenvalues()\n",
        "        return np.max(np.real(eigvals))\n"
      ],
      "metadata": {
        "id": "-N-u50Q1zt_9"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 19: Module 4C — Seizure Criticality Detector ===\n",
        "\n",
        "class SeizureCriticalityDetector:\n",
        "    \"\"\"\n",
        "    Detect proximity to seizure criticality.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, lambda_max):\n",
        "        self.lambda_max = lambda_max\n",
        "\n",
        "    def is_critical(self):\n",
        "        if self.lambda_max > 1.0:\n",
        "            return True\n",
        "        return False\n"
      ],
      "metadata": {
        "id": "fhw_wcK8zy3H"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 20: Run Layer 4 ===\n",
        "\n",
        "def run_layer_4():\n",
        "    \"\"\"\n",
        "    Executes network construction and stability analysis.\n",
        "    \"\"\"\n",
        "\n",
        "    topo = NetworkTopology(n_nodes=100)\n",
        "    G = topo.small_world()\n",
        "    A = topo.adjacency_matrix(G)\n",
        "\n",
        "    stability = JacobianStabilityAnalyzer(A)\n",
        "    lambda_max = stability.max_real_eigenvalue()\n",
        "\n",
        "    detector = SeizureCriticalityDetector(lambda_max)\n",
        "\n",
        "    return {\n",
        "        'AdjacencyMatrix': A,\n",
        "        'LambdaMax': lambda_max,\n",
        "        'IsCritical': detector.is_critical()\n",
        "    }\n"
      ],
      "metadata": {
        "id": "TML3HkPzz1J-"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 21: Module 5A — Cross-Model Consistency Checker ===\n",
        "\n",
        "class CrossModelConsistencyChecker:\n",
        "    \"\"\"\n",
        "    Check consistency across multiple model outputs.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, layer2_results, layer3_results, layer4_results):\n",
        "        self.layer2 = layer2_results\n",
        "        self.layer3 = layer3_results\n",
        "        self.layer4 = layer4_results\n",
        "\n",
        "    def evaluate(self):\n",
        "        \"\"\"\n",
        "        Majority agreement rule.\n",
        "        \"\"\"\n",
        "\n",
        "        flags = []\n",
        "\n",
        "        for res in self.layer2:\n",
        "            hh_activity = res['HH_trace'][:, 0]\n",
        "            if hh_activity.max() > 0:\n",
        "                flags.append(True)\n",
        "            else:\n",
        "                flags.append(False)\n",
        "\n",
        "        wc_activity = self.layer3['WilsonCowan'][:, 0]\n",
        "        flags.append(wc_activity.max() > 0.5)\n",
        "\n",
        "        flags.append(self.layer4['IsCritical'])\n",
        "\n",
        "        return sum(flags) >= (len(flags) // 2 + 1)\n"
      ],
      "metadata": {
        "id": "fe390-kQ1Fo2"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 22: Module 5B — Risk Stratification Engine ===\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "class RiskStratificationEngine:\n",
        "    \"\"\"\n",
        "    Aggregate outputs into a single risk score.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, consistency_flag):\n",
        "        self.consistency_flag = consistency_flag\n",
        "\n",
        "    def compute_risk(self):\n",
        "        \"\"\"\n",
        "        Logistic aggregation.\n",
        "        \"\"\"\n",
        "        x = 1.0 if self.consistency_flag else -1.0\n",
        "        risk = 1 / (1 + np.exp(-x))\n",
        "        return risk\n"
      ],
      "metadata": {
        "id": "NsD4vJg81H7n"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 23: Module 5C — Clinical Interpretation Engine ===\n",
        "\n",
        "class ClinicalInterpretationEngine:\n",
        "    \"\"\"\n",
        "    Generate final clinical interpretation.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, risk_score):\n",
        "        self.risk_score = risk_score\n",
        "\n",
        "    def interpret(self):\n",
        "        if self.risk_score > 0.7:\n",
        "            return \"High seizure risk\"\n",
        "        elif self.risk_score > 0.4:\n",
        "            return \"Moderate seizure risk\"\n",
        "        else:\n",
        "            return \"Low seizure risk\"\n"
      ],
      "metadata": {
        "id": "63kkKkSk1KIu"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 24: Run Layer 5 (Final Integration) ===\n",
        "\n",
        "def run_layer_5(layer2_results, layer3_results, layer4_results):\n",
        "    \"\"\"\n",
        "    Executes final integration and interpretation.\n",
        "    \"\"\"\n",
        "\n",
        "    consistency = CrossModelConsistencyChecker(\n",
        "        layer2_results,\n",
        "        layer3_results,\n",
        "        layer4_results\n",
        "    ).evaluate()\n",
        "\n",
        "    risk_engine = RiskStratificationEngine(consistency)\n",
        "    risk_score = risk_engine.compute_risk()\n",
        "\n",
        "    interpreter = ClinicalInterpretationEngine(risk_score)\n",
        "    interpretation = interpreter.interpret()\n",
        "\n",
        "    return {\n",
        "        'ConsistencyFlag': consistency,\n",
        "        'RiskScore': risk_score,\n",
        "        'Interpretation': interpretation\n",
        "    }\n"
      ],
      "metadata": {
        "id": "FpQio6U41NB9"
      },
      "execution_count": 53,
      "outputs": []
    }
  ]
}